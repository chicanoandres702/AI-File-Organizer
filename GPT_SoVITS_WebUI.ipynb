{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V5E1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chicanoandres702/AI-File-Organizer/blob/main/GPT_SoVITS_WebUI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT-SoVITS-WebUI\n",
        "A Few-shot & Zero-shot Text-to-Speech WebUI.\n",
        "\n",
        "\n",
        "[General GPT-SoVITS Guide](https://rentry.co/GPT-SoVITS-guide#3-initialize-dataset)\n",
        "\n",
        "### Credits:\n",
        "\n",
        "- Original Project & Colab done by [GPT-SoVITS Team](https://github.com/RVC-Boss/GPT-SoVITS/graphs/contributors)\n",
        "\n",
        "- Port made by [Nick088](https://linktr.ee/Nick088)\n",
        "\n",
        "- Testing/Tweaks done by [vulkanitexd](https://discord.com/users/984567398826917918)"
      ],
      "metadata": {
        "id": "_oJOFXTQ0OhD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Prepare the Environment\n",
        "#@markdown It git clones the repository.\n",
        "\n",
        "# get the repo\n",
        "!git clone https://github.com/RVC-Boss/GPT-SoVITS\n",
        "%cd GPT-SoVITS"
      ],
      "metadata": {
        "cellView": "form",
        "id": "RvOEAQx-9wBP",
        "outputId": "8cf5405b-bba0-44c2-8e96-32ef0af419ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GPT-SoVITS'...\n",
            "remote: Enumerating objects: 4172, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 4172 (delta 5), reused 5 (delta 5), pack-reused 4164 (from 3)\u001b[K\n",
            "Receiving objects: 100% (4172/4172), 12.43 MiB | 14.92 MiB/s, done.\n",
            "Resolving deltas: 100% (2425/2425), done.\n",
            "/content/GPT-SoVITS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (OPTIONAL) Mount Google Drive\n",
        "\n",
        "#@markdown This will create a `GPT-SoVITS` folder in [your Google Drive](https://drive.google.com/drive/u/0/home), that can be used to put things like your model dataset, but you have to **manually put the full path** which can be `/content/drive/MyDrive/GPT-SoVITS/YourDatasetHere`\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the parent directory path\n",
        "parent_dir = '/content/drive/MyDrive/GPT-SoVITS'\n",
        "\n",
        "# Create the parent directory if it doesn't exist\n",
        "if not os.path.exists(parent_dir):\n",
        "    os.mkdir(parent_dir)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Zleh7bJOq7DX",
        "outputId": "8ad29084-1039-4ee8-d045-bbb290ef3289",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Conda\n",
        "#@markdown Conda will make the session crash/restart, it's normal, just run the following cells after.\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install_from_url(\"https://repo.anaconda.com/miniconda/Miniconda3-py39_24.11.1-0-Linux-x86_64.sh\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "fMsdGH8AlQgn",
        "outputId": "84f0668e-a7d6-468d-d5e5-cc3d1675d9d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â¬ Downloading https://repo.anaconda.com/miniconda/Miniconda3-py39_24.11.1-0-Linux-x86_64.sh...\n",
            "ðŸ“¦ Installing...\n",
            "ðŸ“Œ Adjusting configuration...\n",
            "ðŸ©¹ Patching environment...\n",
            "â² Done in 0:00:23\n",
            "ðŸ” Restarting kernel...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install requirements\n",
        "#@markdown Will take alot of time..\n",
        "\n",
        "#@markdown The runtime will restart itself, it's normal.\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "\n",
        "%cd /content/GPT-SoVITS/\n",
        "!bash install.sh\n",
        "\n",
        "# fix packages asr models japanese/english (whisper)\n",
        "!pip install ctranslate2==4.4.0\n",
        "\n",
        "# fix https://github.com/RVC-Boss/GPT-SoVITS/issues/1715\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "# fix for issue in inference\n",
        "!pip install -q ipykernel\n",
        "\n",
        "# fix train gpt\n",
        "!pip install torchmetrics==1.5\n",
        "\n",
        "clear_output()\n",
        "\n",
        "print(\"Installed the requirements!\")\n",
        "\n",
        "time.sleep(5)\n",
        "# restart runtime\n",
        "import os\n",
        "os._exit(0)"
      ],
      "metadata": {
        "id": "afNtr2lXyuKQ",
        "cellView": "form",
        "outputId": "2d129ca7-239f-4eba-d06b-04e3cf751dad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installed the requirements!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download Pretrained Models\n",
        "#@markdown gpt so vits v1 & v2 pretrains + uvr5 weights + chinese asr. (english/japanese asr, faster whisper, should be automatically installed when using it for ASR in the UI)\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "\n",
        "%cd /content/\n",
        "\n",
        "\n",
        "# gpt so vits pretrains\n",
        "\n",
        "!git clone https://huggingface.co/lj1995/GPT-SoVITS/ gptsovits_pretrains_temp\n",
        "\n",
        "!mv gptsovits_pretrains_temp/* GPT-SoVITS/GPT_SoVITS/pretrained_models/\n",
        "\n",
        "!rm -rf gptsovits_pretrains_temp\n",
        "\n",
        "\n",
        "# uvr5 weights\n",
        "\n",
        "!git clone https://huggingface.co/Delik/uvr5_weights uvr5_weights_temp\n",
        "\n",
        "!mv uvr5_weights_temp/* GPT-SoVITS/tools/uvr5/uvr5_weights\n",
        "\n",
        "!rm -rf uvr5_weights_temp\n",
        "\n",
        "\n",
        "# Chinese ASR models\n",
        "\n",
        "%cd /content/GPT-SoVITS/tools/asr/models\n",
        "!git clone https://www.modelscope.cn/damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch.git\n",
        "!git clone https://www.modelscope.cn/damo/speech_fsmn_vad_zh-cn-16k-common-pytorch.git\n",
        "!git clone https://www.modelscope.cn/damo/punc_ct-transformer_zh-cn-common-vocab272727-pytorch.git\n",
        "\n",
        "# English/Japanese ASR should be automatically downloaded.\n",
        "\n",
        "clear_output()\n",
        "print(\"Downloaded!\")"
      ],
      "metadata": {
        "id": "ym6l8aAiBjKj",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run UI\n",
        "\n",
        "#@markdown The first run may take more time as it will download the g2pw model.\n",
        "\n",
        "#@markdown The type of tunnel you wanna use for seeing the public link, so that if one of them is down, you can use the other one.\n",
        "Tunnel = \"Gradio\" #@param [\"Gradio\", \"Ngrok\", \"Cloudflare\", \"LocalTunnel\", \"Horizon\"]\n",
        "\n",
        "#@markdown Also when using Ngrok ,Cloudflare, LocalTunnel, or Horizon, you need to wait for the Local URL to appear, and only after that click on the Public URL which is above. Plus, you have to open UVR in the GPT-SoVITS UI before opening the Public URL.\n",
        "\n",
        "\n",
        "#@markdown Use the following option **only if you chose Ngrok** as the Tunnel, **You need to be a paid ngrok member** as it needs more than 3 tunnels (there are 4 ports):\n",
        "\n",
        "#@markdown You can get the Ngrok Tunnel Authtoken here: https://dashboard.ngrok.com/tunnels/authtokens/new.\n",
        "\n",
        "ngrok_tunnel_authtoken = \"\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "#@markdown Use the following option **only if you chose Horizon** as the Tunnel:\n",
        "\n",
        "#@markdown You can get the Horizon ID here: https://hrzn.run/dashboard/ , login, on the 2nd step, it shows an `hrzn login YOUR_ID`, you need to copy that id.\n",
        "\n",
        "horizon_id = \"\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "\n",
        "%cd /content/GPT-SoVITS/\n",
        "\n",
        "\n",
        "if Tunnel == \"Gradio\":\n",
        "  %env is_share = True\n",
        "elif Tunnel == \"Ngrok\":\n",
        "  %env is_share = False\n",
        "  !pip install pyngrok\n",
        "  from pyngrok import ngrok\n",
        "  ngrok.set_auth_token(ngrok_tunnel_authtoken)\n",
        "  gptsovits_tunnel = ngrok.connect(9874, bind_tls=True)\n",
        "  uvr_tunnel = ngrok.connect(9873, bind_tls=True)\n",
        "  inference_tunnel = ngrok.connect(9872, bind_tls=True)\n",
        "  proofreading_tunnel = ngrok.connect(9871, bind_tls=True)\n",
        "  print(\"GPT-SoVITS Tunnel Public URL:\", gptsovits_tunnel.public_url)\n",
        "  print(\"UVR Tunnel Public URL:\", uvr_tunnel.public_url)\n",
        "  print(\"Inference Tunnel Public URL:\", uvr_tunnel.public_url)\n",
        "  print(\"Proofreading Tunnel Public URL:\", proofreading_tunnel.public_url)\n",
        "elif Tunnel == \"Cloudflare\":\n",
        "  %env is_share = False\n",
        "  # download cloudflare\n",
        "  !curl -LO https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "  !dpkg -i cloudflared-linux-amd64.deb\n",
        "  !rm -rf nohup.out\n",
        "  import time\n",
        "  # Run cloudflare\n",
        "  # gpt so vits\n",
        "  !nohup cloudflared tunnel --url localhost:9874 &\n",
        "  time.sleep(7)\n",
        "  # uvr\n",
        "  !nohup cloudflared tunnel --url localhost:9873 &\n",
        "  time.sleep(7)\n",
        "  # inference\n",
        "  !nohup cloudflared tunnel --url localhost:9872 &\n",
        "  time.sleep(7)\n",
        "  # proofreading\n",
        "  !nohup cloudflared tunnel --url localhost:9871 &\n",
        "  clear_output()\n",
        "  time.sleep(7)\n",
        "  # Find and print the Cloudflare URL with a prefix\n",
        "  cloudflare_url = !grep -oE \"https://[a-zA-Z0-9.-]+\\.trycloudflare\\.com\" nohup.out\n",
        "  print(f\"GPT-SoVITS Tunnel Public URL: {cloudflare_url[0]}\")\n",
        "  print(f\"UVR Tunnel Public URL: {cloudflare_url[1]}\")\n",
        "  print(f\"Inference Tunnel Public URL: {cloudflare_url[2]}\")\n",
        "  print(f\"Proofreading Tunnel Public URL: {cloudflare_url[3]}\")\n",
        "elif Tunnel == \"LocalTunnel\":\n",
        "  %env is_share = False\n",
        "  # install\n",
        "  !npm install -g localtunnel\n",
        "  import time\n",
        "  import urllib\n",
        "  # run localtunnel\n",
        "  # gptsovits\n",
        "  with open('url.txt', 'w') as file:\n",
        "        file.write('')\n",
        "\n",
        "  get_ipython().system_raw('lt --port 9874 >> url.txt 2>&1 &')\n",
        "\n",
        "  time.sleep(4)\n",
        "\n",
        "  endpoint_ip = urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\")\n",
        "\n",
        "  with open('url.txt', 'r') as file:\n",
        "      tunnel_url = file.read()\n",
        "      tunnel_url = tunnel_url.replace(\"your url is: \", \"\")\n",
        "\n",
        "  clear_output()\n",
        "\n",
        "  print(f\"GPT-SoVITS Tunnel Public URL: \\033[0m\\033[93m{tunnel_url}\\033[0m\", end=\"\\033[0m\")\n",
        "\n",
        "  # uvr\n",
        "  with open('url2.txt', 'w') as file:\n",
        "        file.write('')\n",
        "\n",
        "  get_ipython().system_raw('lt --port 9873 >> url2.txt 2>&1 &')\n",
        "\n",
        "  time.sleep(4)\n",
        "\n",
        "  endpoint_ip = urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\")\n",
        "\n",
        "  with open('url2.txt', 'r') as file:\n",
        "      tunnel_url = file.read()\n",
        "      tunnel_url = tunnel_url.replace(\"your url is: \", \"\")\n",
        "\n",
        "  print(f\"UVR Tunnel Public URL: \\033[0m\\033[93m{tunnel_url}\\033[0m\", end=\"\\033[0m\")\n",
        "\n",
        "  # inference\n",
        "  with open('url3.txt', 'w') as file:\n",
        "        file.write('')\n",
        "\n",
        "  get_ipython().system_raw('lt --port 9872 >> url3.txt 2>&1 &')\n",
        "\n",
        "  time.sleep(4)\n",
        "\n",
        "  endpoint_ip = urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\")\n",
        "\n",
        "  with open('url3.txt', 'r') as file:\n",
        "      tunnel_url = file.read()\n",
        "      tunnel_url = tunnel_url.replace(\"your url is: \", \"\")\n",
        "\n",
        "  print(f\"Inference Tunnel Public URL: \\033[0m\\033[93m{tunnel_url}\\033[0m\", end=\"\\033[0m\")\n",
        "\n",
        "  # proofreading\n",
        "  with open('url4.txt', 'w') as file:\n",
        "        file.write('')\n",
        "\n",
        "  get_ipython().system_raw('lt --port 9871 >> url4.txt 2>&1 &')\n",
        "\n",
        "  time.sleep(4)\n",
        "\n",
        "  endpoint_ip = urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\")\n",
        "\n",
        "  with open('url4.txt', 'r') as file:\n",
        "      tunnel_url = file.read()\n",
        "      tunnel_url = tunnel_url.replace(\"your url is: \", \"\")\n",
        "\n",
        "  print(f\"Proofreading Tunnel Public URL: \\033[0m\\033[93m{tunnel_url}\\033[0m\", end=\"\\033[0m\")\n",
        "\n",
        "\n",
        "  print(f'LocalTunnels Password: {endpoint_ip}')\n",
        "elif Tunnel == \"Horizon\":\n",
        "  # install\n",
        "  !npm install -g @hrzn/cli\n",
        "  # login\n",
        "  !hrzn login $horizon_id\n",
        "  # run horizon\n",
        "  # gptsovits\n",
        "  with open('url.txt', 'w') as file:\n",
        "        file.write('')\n",
        "\n",
        "  get_ipython().system_raw('hrzn tunnel http://localhost:9874 >> url.txt 2>&1 &')\n",
        "\n",
        "  time.sleep(4)\n",
        "\n",
        "  with open('url.txt', 'r') as file:\n",
        "      tunnel_url = file.read()\n",
        "      tunnel_url = !grep -oE \"https://[a-zA-Z0-9.-]+\\.hrzn\\.run\" url.txt\n",
        "      tunnel_url = tunnel_url[0]\n",
        "\n",
        "  clear_output()\n",
        "\n",
        "  print(f\"GPT-SoVITS Tunnel Public URL: \\033[0m\\033[93m{tunnel_url}\\033[0m\")\n",
        "\n",
        "  # uvr\n",
        "  with open('url.txt', 'w') as file:\n",
        "        file.write('')\n",
        "\n",
        "  get_ipython().system_raw('hrzn tunnel http://localhost:9873 >> url2.txt 2>&1 &')\n",
        "\n",
        "  time.sleep(4)\n",
        "\n",
        "  with open('url2.txt', 'r') as file:\n",
        "      tunnel_url = file.read()\n",
        "      tunnel_url = !grep -oE \"https://[a-zA-Z0-9.-]+\\.hrzn\\.run\" url2.txt\n",
        "      tunnel_url = tunnel_url[0]\n",
        "\n",
        "  print(f\"UVR Tunnel Public URL: \\033[0m\\033[93m{tunnel_url}\\033[0m\")\n",
        "\n",
        "  # inference\n",
        "  with open('url3.txt', 'w') as file:\n",
        "        file.write('')\n",
        "\n",
        "  get_ipython().system_raw('hrzn tunnel http://localhost:9872 >> url3.txt 2>&1 &')\n",
        "\n",
        "  time.sleep(4)\n",
        "\n",
        "  with open('url3.txt', 'r') as file:\n",
        "      tunnel_url = file.read()\n",
        "      tunnel_url = !grep -oE \"https://[a-zA-Z0-9.-]+\\.hrzn\\.run\" url3.txt\n",
        "      tunnel_url = tunnel_url[0]\n",
        "\n",
        "  print(f\"Inference Tunnel Public URL: \\033[0m\\033[93m{tunnel_url}\\033[0m\")\n",
        "\n",
        "  # proofreading\n",
        "  with open('url4.txt', 'w') as file:\n",
        "        file.write('')\n",
        "\n",
        "  get_ipython().system_raw('hrzn tunnel http://localhost:9871 >> url4.txt 2>&1 &')\n",
        "\n",
        "  time.sleep(4)\n",
        "\n",
        "  with open('url4.txt', 'r') as file:\n",
        "      tunnel_url = file.read()\n",
        "      tunnel_url = !grep -oE \"https://[a-zA-Z0-9.-]+\\.hrzn\\.run\" url4.txt\n",
        "      tunnel_url = tunnel_url[0]\n",
        "\n",
        "  print(f\"Proofreading Tunnel Public URL: \\033[0m\\033[93m{tunnel_url}\\033[0m\")\n",
        "\n",
        "\n",
        "import subprocess\n",
        "!python webui.py"
      ],
      "metadata": {
        "id": "Otq5d5-Z7xZL",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}